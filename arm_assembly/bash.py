#!/usr/bin/env python3
"""
x86_64_O0 åç¼€æ–‡ä»¶æ¸…ç†è„šæœ¬
åŠŸèƒ½ï¼šå®‰å…¨åˆ é™¤å¸¦æœ‰ _x86_64_O0 åç¼€çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
"""

import os
import sys
import argparse
from pathlib import Path
from typing import List, Dict, Set, Tuple
import re
import shutil
from datetime import datetime
import logging
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'x86_cleanup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class X86O0FileCleaner:
    """x86_64_O0 æ–‡ä»¶æ¸…ç†å™¨"""
    
    # å®šä¹‰ç›®æ ‡åç¼€æ¨¡å¼
    TARGET_SUFFIXES = {
        'primary': ['_x86_64_O0.s', '_x86_64_O0.S'],  # ä¸»è¦ç›®æ ‡åç¼€
        'variations': [  # å¯èƒ½çš„å˜ä½“
            '_x86_64_o0.s', '_x86_64_o0.S',
            '_x86_64_O0', '_x86_64_o0',
            '_x86_O0.s', '_x86_o0.s',
            'x86_64_O0.s', 'x86_64_o0.s'
        ],
        'related': [  # ç›¸å…³æ–‡ä»¶åç¼€
            '_x86_64_O1.s', '_x86_64_O2.s', '_x86_64_O3.s',
            '_x86_64_Os.s', '_x86_64_Oz.s'
        ]
    }
    
    def __init__(self, dry_run: bool = False, backup: bool = False, 
                 include_variations: bool = False, include_related: bool = False,
                 min_size: int = 0, max_size: int = 0):
        self.dry_run = dry_run
        self.backup = backup
        self.include_variations = include_variations
        self.include_related = include_related
        self.min_size = min_size
        self.max_size = max_size
        self.backup_dir = None
        self.stats = {
            'total_scanned': 0,
            'files_found': 0,
            'folders_found': 0,
            'files_deleted': 0,
            'folders_deleted': 0,
            'files_backed_up': 0,
            'total_freed': 0,
            'errors': 0
        }
        
        if self.backup:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            self.backup_dir = Path(f"backup_x86_files_{timestamp}")
            self.backup_dir.mkdir(exist_ok=True)
            logger.info(f"ğŸ“¦ å¤‡ä»½ç›®å½•: {self.backup_dir}")
    
    def get_target_patterns(self) -> List[str]:
        """è·å–ç›®æ ‡æ¨¡å¼åˆ—è¡¨"""
        patterns = self.TARGET_SUFFIXES['primary'].copy()
        
        if self.include_variations:
            patterns.extend(self.TARGET_SUFFIXES['variations'])
        
        if self.include_related:
            patterns.extend(self.TARGET_SUFFIXES['related'])
        
        return patterns
    
    def is_target_file(self, filename: str) -> Tuple[bool, str, str]:
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºx86_64_O0ç›®æ ‡æ–‡ä»¶"""
        patterns = self.get_target_patterns()
        
        for pattern in patterns:
            # ç²¾ç¡®åŒ¹é…åç¼€
            if filename.endswith(pattern):
                return True, 'exact_suffix', f"ç²¾ç¡®åŒ¹é…åç¼€: {pattern}"
            
            # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼ˆå¤„ç†å¤§å°å†™å˜ä½“ï¼‰
            regex_pattern = pattern.replace('_', '[_-]?').replace('O0', '[Oo]0')
            if re.search(f'{regex_pattern}$', filename, re.IGNORECASE):
                return True, 'regex_match', f"æ­£åˆ™åŒ¹é…: {pattern}"
        
        # æ£€æŸ¥æ–‡ä»¶åä¸­åŒ…å«ç›®æ ‡å…³é”®è¯
        keywords = ['x86_64_O0', 'x86_64_o0', 'x86_O0', 'x86_o0']
        for keyword in keywords:
            if keyword.lower() in filename.lower():
                return True, 'keyword', f"åŒ…å«å…³é”®è¯: {keyword}"
        
        return False, '', "ä¸æ˜¯ç›®æ ‡æ–‡ä»¶"
    
    def is_target_folder(self, foldername: str) -> Tuple[bool, str, str]:
        """åˆ¤æ–­æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºx86ç›¸å…³æ–‡ä»¶å¤¹"""
        folder_patterns = [
            'x86', 'x86_64', 'x86_files', 'x86_assembly',
            'x86_O0', 'x86_64_O0', 'matched_pairs'
        ]
        
        for pattern in folder_patterns:
            if pattern.lower() in foldername.lower():
                return True, 'folder_pattern', f"æ–‡ä»¶å¤¹åŒ¹é…: {pattern}"
        
        return False, '', "ä¸æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹"
    
    def should_process_file(self, filepath: Path) -> Tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¯¥æ–‡ä»¶"""
        if not filepath.exists():
            return False, "æ–‡ä»¶ä¸å­˜åœ¨"
        
        if not filepath.is_file():
            return False, "ä¸æ˜¯æ–‡ä»¶"
        
        try:
            file_size = filepath.stat().st_size
            
            if self.min_size > 0 and file_size < self.min_size:
                return False, f"æ–‡ä»¶å¤ªå° ({file_size} < {self.min_size})"
            
            if self.max_size > 0 and file_size > self.max_size:
                return False, f"æ–‡ä»¶å¤ªå¤§ ({file_size} > {self.max_size})"
            
            return True, f"å¤§å°: {self.format_size(file_size)}"
            
        except Exception as e:
            return False, f"æ— æ³•è®¿é—®æ–‡ä»¶: {e}"
    
    def should_process_folder(self, folderpath: Path) -> Tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¯¥æ–‡ä»¶å¤¹"""
        if not folderpath.exists():
            return False, "æ–‡ä»¶å¤¹ä¸å­˜åœ¨"
        
        if not folderpath.is_dir():
            return False, "ä¸æ˜¯æ–‡ä»¶å¤¹"
        
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©º
            if any(folderpath.iterdir()):
                return True, "æ–‡ä»¶å¤¹éç©º"
            else:
                return True, "ç©ºæ–‡ä»¶å¤¹"
                
        except Exception as e:
            return False, f"æ— æ³•è®¿é—®æ–‡ä»¶å¤¹: {e}"
    
    def backup_file(self, filepath: Path) -> bool:
        """å¤‡ä»½æ–‡ä»¶"""
        if not self.backup or not self.backup_dir:
            return True
        
        try:
            # ä¿æŒç›®å½•ç»“æ„
            relative_path = filepath.relative_to(Path.cwd()) if filepath.is_relative_to(Path.cwd()) else filepath
            backup_path = self.backup_dir / relative_path
            
            # åˆ›å»ºçˆ¶ç›®å½•
            backup_path.parent.mkdir(parents=True, exist_ok=True)
            
            shutil.copy2(filepath, backup_path)
            logger.debug(f"å¤‡ä»½æ–‡ä»¶: {filepath} -> {backup_path}")
            self.stats['files_backed_up'] += 1
            return True
            
        except Exception as e:
            logger.error(f"å¤‡ä»½æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
            return False
    
    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"
    
    def delete_file(self, filepath: Path) -> bool:
        """åˆ é™¤æ–‡ä»¶"""
        try:
            if self.dry_run:
                file_size = filepath.stat().st_size
                logger.info(f"ğŸ—‘ï¸ [æ¨¡æ‹Ÿ] åˆ é™¤æ–‡ä»¶: {filepath.name} ({self.format_size(file_size)})")
                return True
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = filepath.stat().st_size
            
            # å¤‡ä»½ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not self.backup_file(filepath):
                return False
            
            # å®é™…åˆ é™¤
            filepath.unlink()
            logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {filepath.name} ({self.format_size(file_size)})")
            
            self.stats['files_deleted'] += 1
            self.stats['total_freed'] += file_size
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
            self.stats['errors'] += 1
            return False
    
    def delete_folder(self, folderpath: Path) -> bool:
        """åˆ é™¤æ–‡ä»¶å¤¹"""
        try:
            if self.dry_run:
                logger.info(f"ğŸ“ [æ¨¡æ‹Ÿ] åˆ é™¤æ–‡ä»¶å¤¹: {folderpath.name}")
                return True
            
            # é€’å½’åˆ é™¤æ–‡ä»¶å¤¹
            shutil.rmtree(folderpath)
            logger.info(f"ğŸ“ åˆ é™¤æ–‡ä»¶å¤¹: {folderpath.name}")
            
            self.stats['folders_deleted'] += 1
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡ä»¶å¤¹å¤±è´¥ {folderpath}: {e}")
            self.stats['errors'] += 1
            return False
    
    def scan_directory(self, directory: Path, recursive: bool = True) -> Tuple[List[Dict], List[Dict]]:
        """æ‰«æç›®å½•ä¸­çš„ç›®æ ‡æ–‡ä»¶å’Œæ–‡ä»¶å¤¹"""
        target_files = []
        target_folders = []
        
        try:
            if recursive:
                iterator = directory.rglob('*')  # é€’å½’
            else:
                iterator = directory.glob('*')   # éé€’å½’
            
            for item in iterator:
                self.stats['total_scanned'] += 1
                
                if item.is_file():
                    # æ£€æŸ¥æ–‡ä»¶
                    is_target, pattern, reason = self.is_target_file(item.name)
                    if is_target:
                        should_process, process_reason = self.should_process_file(item)
                        
                        file_info = {
                            'type': 'file',
                            'path': str(item),
                            'name': item.name,
                            'size': item.stat().st_size,
                            'pattern': pattern,
                            'reason': reason,
                            'should_process': should_process,
                            'process_reason': process_reason
                        }
                        
                        target_files.append(file_info)
                        self.stats['files_found'] += 1
                        
                        if self.stats['files_found'] <= 3:
                            status = "å¯å¤„ç†" if should_process else "è·³è¿‡"
                            logger.info(f"ğŸ” å‘ç°ç›®æ ‡æ–‡ä»¶: {item.name} ({status})")
                
                elif item.is_dir():
                    # æ£€æŸ¥æ–‡ä»¶å¤¹
                    is_target, pattern, reason = self.is_target_folder(item.name)
                    if is_target:
                        should_process, process_reason = self.should_process_folder(item)
                        
                        folder_info = {
                            'type': 'folder',
                            'path': str(item),
                            'name': item.name,
                            'pattern': pattern,
                            'reason': reason,
                            'should_process': should_process,
                            'process_reason': process_reason
                        }
                        
                        target_folders.append(folder_info)
                        self.stats['folders_found'] += 1
                        
                        if self.stats['folders_found'] <= 3:
                            status = "å¯å¤„ç†" if should_process else "è·³è¿‡"
                            logger.info(f"ğŸ“ å‘ç°ç›®æ ‡æ–‡ä»¶å¤¹: {item.name} ({status})")
        
        except Exception as e:
            logger.error(f"æ‰«æç›®å½•å¤±è´¥ {directory}: {e}")
        
        return target_files, target_folders
    
    def generate_report(self, target_files: List[Dict], target_folders: List[Dict], directory: Path) -> Dict:
        """ç”ŸæˆæŠ¥å‘Š"""
        processed_files = [f for f in target_files if f['should_process']]
        processed_folders = [f for f in target_folders if f['should_process']]
        
        # æŒ‰æ¨¡å¼ç»Ÿè®¡æ–‡ä»¶
        file_pattern_stats = {}
        for file in target_files:
            pattern = file['pattern']
            if pattern not in file_pattern_stats:
                file_pattern_stats[pattern] = 0
            file_pattern_stats[pattern] += 1
        
        # æŒ‰æ¨¡å¼ç»Ÿè®¡æ–‡ä»¶å¤¹
        folder_pattern_stats = {}
        for folder in target_folders:
            pattern = folder['pattern']
            if pattern not in folder_pattern_stats:
                folder_pattern_stats[pattern] = 0
            folder_pattern_stats[pattern] += 1
        
        return {
            'timestamp': datetime.now().isoformat(),
            'config': {
                'directory': str(directory),
                'dry_run': self.dry_run,
                'backup': self.backup,
                'include_variations': self.include_variations,
                'include_related': self.include_related,
                'min_size': self.min_size,
                'max_size': self.max_size,
                'backup_dir': str(self.backup_dir) if self.backup_dir else None
            },
            'statistics': {
                'total_items_scanned': self.stats['total_scanned'],
                'target_files_found': self.stats['files_found'],
                'target_folders_found': self.stats['folders_found'],
                'files_processed': len(processed_files),
                'folders_processed': len(processed_folders),
                'files_deleted': self.stats['files_deleted'],
                'folders_deleted': self.stats['folders_deleted'],
                'files_backed_up': self.stats['files_backed_up'],
                'total_space_freed': self.stats['total_freed'],
                'total_space_freed_formatted': self.format_size(self.stats['total_freed']),
                'errors': self.stats['errors']
            },
            'pattern_statistics': {
                'files': file_pattern_stats,
                'folders': folder_pattern_stats
            },
            'target_patterns': self.get_target_patterns(),
            'processed_files': processed_files,
            'processed_folders': processed_folders
        }
    
    def print_report(self, report: Dict):
        """æ‰“å°æŠ¥å‘Š"""
        stats = report['statistics']
        config = report['config']
        patterns = report['target_patterns']
        
        print("\n" + "="*70)
        print("x86_64_O0 æ–‡ä»¶æ¸…ç†æŠ¥å‘Š")
        print("="*70)
        print(f"æ—¶é—´: {report['timestamp']}")
        print(f"æ‰«æç›®å½•: {config['directory']}")
        print(f"å¹²è¿è¡Œæ¨¡å¼: {'æ˜¯' if config['dry_run'] else 'å¦'}")
        print(f"å¤‡ä»½æ¨¡å¼: {'æ˜¯' if config['backup'] else 'å¦'}")
        print(f"åŒ…å«å˜ä½“: {'æ˜¯' if config['include_variations'] else 'å¦'}")
        print(f"åŒ…å«ç›¸å…³æ–‡ä»¶: {'æ˜¯' if config['include_related'] else 'å¦'}")
        print(f"ç›®æ ‡æ¨¡å¼: {', '.join(patterns[:3])}...")
        print()
        
        # ç»Ÿè®¡ä¿¡æ¯
        print("ğŸ“Š æ‰«æç»Ÿè®¡:")
        print(f"  æ‰«æé¡¹ç›®æ€»æ•°: {stats['total_items_scanned']}")
        print(f"  å‘ç°ç›®æ ‡æ–‡ä»¶: {stats['target_files_found']}")
        print(f"  å‘ç°ç›®æ ‡æ–‡ä»¶å¤¹: {stats['target_folders_found']}")
        print(f"  å¯å¤„ç†æ–‡ä»¶: {stats['files_processed']}")
        print(f"  å¯å¤„ç†æ–‡ä»¶å¤¹: {stats['folders_processed']}")
        print(f"  å®é™…åˆ é™¤æ–‡ä»¶: {stats['files_deleted']}")
        print(f"  å®é™…åˆ é™¤æ–‡ä»¶å¤¹: {stats['folders_deleted']}")
        print(f"  å¤‡ä»½æ–‡ä»¶: {stats['files_backed_up']}")
        print(f"  é‡Šæ”¾ç©ºé—´: {stats['total_space_freed_formatted']}")
        print(f"  é”™è¯¯æ•°: {stats['errors']}")
        print()
        
        # æ¨¡å¼ç»Ÿè®¡
        pattern_stats = report['pattern_statistics']
        if pattern_stats['files']:
            print("ğŸ” æ–‡ä»¶åŒ¹é…æ¨¡å¼ç»Ÿè®¡:")
            for pattern, count in sorted(pattern_stats['files'].items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  {pattern}: {count} ä¸ªæ–‡ä»¶")
        
        if pattern_stats['folders']:
            print("ğŸ“ æ–‡ä»¶å¤¹åŒ¹é…æ¨¡å¼ç»Ÿè®¡:")
            for pattern, count in sorted(pattern_stats['folders'].items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  {pattern}: {count} ä¸ªæ–‡ä»¶å¤¹")
        print()
        
        # å¤„ç†çš„æ–‡ä»¶
        processed_files = report['processed_files']
        if processed_files:
            print(f"ğŸ—‘ï¸ å¤„ç†çš„æ–‡ä»¶ ({len(processed_files)}):")
            for i, file in enumerate(processed_files[:8]):
                status = "[æ¨¡æ‹Ÿ] " if config['dry_run'] else ""
                print(f"  {i+1}. {file['name']} ({self.format_size(file['size'])})")
                print(f"     æ¨¡å¼: {file['pattern']} - {file['reason']}")
            if len(processed_files) > 8:
                print(f"  ... è¿˜æœ‰ {len(processed_files)-8} ä¸ªæ–‡ä»¶")
            print()
        
        # å¤„ç†çš„æ–‡ä»¶å¤¹
        processed_folders = report['processed_folders']
        if processed_folders:
            print(f"ğŸ“ å¤„ç†çš„æ–‡ä»¶å¤¹ ({len(processed_folders)}):")
            for i, folder in enumerate(processed_folders[:5]):
                status = "[æ¨¡æ‹Ÿ] " if config['dry_run'] else ""
                print(f"  {i+1}. {folder['name']}")
                print(f"     æ¨¡å¼: {folder['pattern']} - {folder['reason']}")
            if len(processed_folders) > 5:
                print(f"  ... è¿˜æœ‰ {len(processed_folders)-5} ä¸ªæ–‡ä»¶å¤¹")
            print()
        
        # æ€»ç»“
        if config['dry_run']:
            print("ğŸ’¡ å¹²è¿è¡Œæ¨¡å¼å®Œæˆ - æ²¡æœ‰å®é™…åˆ é™¤")
            print("   ä½¿ç”¨ --execute å‚æ•°å®é™…æ‰§è¡Œåˆ é™¤æ“ä½œ")
        else:
            if stats['files_deleted'] > 0 or stats['folders_deleted'] > 0:
                print(f"ğŸ‰ æ¸…ç†å®Œæˆ! é‡Šæ”¾äº† {stats['total_space_freed_formatted']} ç©ºé—´")
            else:
                print("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°å¯åˆ é™¤çš„ç›®æ ‡æ–‡ä»¶")
        
        print("="*70)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="x86_64_O0 æ–‡ä»¶æ¸…ç†å·¥å…·")
    parser.add_argument("directory", nargs="?", default=".", 
                       help="è¦æ‰«æçš„ç›®å½•ï¼ˆé»˜è®¤: å½“å‰ç›®å½•ï¼‰")
    parser.add_argument("--execute", action="store_true",
                       help="å®é™…æ‰§è¡Œåˆ é™¤æ“ä½œï¼ˆé»˜è®¤: å¹²è¿è¡Œæ¨¡å¼ï¼‰")
    parser.add_argument("--backup", "-b", action="store_true",
                       help="åˆ é™¤å‰å¤‡ä»½æ–‡ä»¶")
    parser.add_argument("--include-variations", "-v", action="store_true",
                       help="åŒ…å«å˜ä½“åç¼€ï¼ˆå¦‚ _x86_64_o0.s, _x86_O0.s ç­‰ï¼‰")
    parser.add_argument("--include-related", "-r", action="store_true",
                       help="åŒ…å«ç›¸å…³æ–‡ä»¶ï¼ˆå¦‚ _x86_64_O1.s, _x86_64_O2.s ç­‰ï¼‰")
    parser.add_argument("--recursive", "-R", action="store_true", default=True,
                       help="é€’å½’æ‰«æå­ç›®å½•ï¼ˆé»˜è®¤: æ˜¯ï¼‰")
    parser.add_argument("--no-recursive", action="store_true",
                       help="ä¸é€’å½’æ‰«æå­ç›®å½•")
    parser.add_argument("--min-size", type=int, default=0,
                       help="æœ€å°æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰")
    parser.add_argument("--max-size", type=int, default=0,
                       help="æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼Œ0è¡¨ç¤ºæ— é™åˆ¶ï¼‰")
    parser.add_argument("--verbose", action="store_true",
                       help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--json", action="store_true",
                       help="è¾“å‡ºJSONæ ¼å¼æŠ¥å‘Š")
    parser.add_argument("--output", default="x86_cleanup_report.json",
                       help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # å¤„ç†é€’å½’é€‰é¡¹
    recursive = args.recursive and not args.no_recursive
    
    try:
        target_dir = Path(args.directory)
        if not target_dir.exists():
            logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {target_dir}")
            return 1
        
        # åˆ›å»ºæ¸…ç†å™¨
        cleaner = X86O0FileCleaner(
            dry_run=not args.execute,
            backup=args.backup,
            include_variations=args.include_variations,
            include_related=args.include_related,
            min_size=args.min_size,
            max_size=args.max_size
        )
        
        logger.info(f"ğŸ” å¼€å§‹æ‰«æç›®å½•: {target_dir}")
        logger.info(f"ç›®æ ‡æ¨¡å¼: {', '.join(cleaner.get_target_patterns()[:3])}...")
        logger.info(f"é€’å½’æ‰«æ: {'æ˜¯' if recursive else 'å¦'}")
        logger.info(f"å¹²è¿è¡Œæ¨¡å¼: {'æ˜¯' if not args.execute else 'å¦'}")
        
        # æ‰«æç›®å½•
        target_files, target_folders = cleaner.scan_directory(target_dir, recursive)
        
        if not target_files and not target_folders:
            logger.info("âœ… æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹")
            return 0
        
        # å¤„ç†æ–‡ä»¶
        for file_info in target_files:
            if file_info['should_process']:
                filepath = Path(file_info['path'])
                cleaner.delete_file(filepath)
        
        # å¤„ç†æ–‡ä»¶å¤¹ï¼ˆå…ˆå¤„ç†æ–‡ä»¶ï¼Œå†å¤„ç†æ–‡ä»¶å¤¹ï¼‰
        for folder_info in target_folders:
            if folder_info['should_process']:
                folderpath = Path(folder_info['path'])
                cleaner.delete_folder(folderpath)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = cleaner.generate_report(target_files, target_folders, target_dir)
        
        # æ‰“å°æŠ¥å‘Š
        cleaner.print_report(report)
        
        # ä¿å­˜JSONæŠ¥å‘Š
        if args.json:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ JSONæŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        
        return 0
        
    except KeyboardInterrupt:
        logger.info("æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())